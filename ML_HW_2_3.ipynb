{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML HW #2.3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/larrymoralez/ML_HW_-2/blob/master/ML_HW_2_3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "WB2MOX36BTBN",
        "colab_type": "code",
        "outputId": "57bee917-eb9e-4d75-be44-77ae94daec18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Import libraries\n",
        "import numpy as np\n",
        "from matplotlib import pyplot\n",
        "import keras\n",
        "from keras.datasets import cifar10\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 53s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6o9sdnPXBZdH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#split data into training and test data. Be careful to only run once or it will split data over and over again.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1kCX5qUQBZ86",
        "colab_type": "code",
        "outputId": "167b10e8-2354-4224-8025-c88a2b1bc5e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "cell_type": "code",
      "source": [
        "#Set initial params\n",
        "batch_size = 32\n",
        "num_classes = 10\n",
        "epochs = 100\n",
        "RMS = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DtWArztVBcWk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Convert labels to categroical\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMIDxPB5BeqB",
        "colab_type": "code",
        "outputId": "53f5fde8-bf30-49ea-ad4b-9b07f8975dc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "#Define model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=x_train.shape[1:]))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same'))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 32, 32, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 30, 30, 32)        9248      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 30, 30, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 15, 15, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 15, 15, 64)        18496     \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 15, 15, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 64)        36928     \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 64)        0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 6, 6, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                5130      \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 1,250,858\n",
            "Trainable params: 1,250,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1ne3nMXyFLUQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Compile model\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=RMS,\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eztZhQ-YFO7U",
        "colab_type": "code",
        "outputId": "499d2c95-b351-4b30-e0f9-2a820faf06c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1683
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, batch_size = batch_size, epochs = epochs, validation_data=(x_val, y_val), shuffle = True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 40000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "40000/40000 [==============================] - 224s 6ms/step - loss: 2.4247 - acc: 0.3053 - val_loss: 1.5202 - val_acc: 0.4547\n",
            "Epoch 2/100\n",
            "40000/40000 [==============================] - 226s 6ms/step - loss: 1.5222 - acc: 0.4484 - val_loss: 1.3813 - val_acc: 0.5093\n",
            "Epoch 3/100\n",
            "40000/40000 [==============================] - 227s 6ms/step - loss: 1.3625 - acc: 0.5167 - val_loss: 1.2243 - val_acc: 0.5748\n",
            "Epoch 4/100\n",
            "40000/40000 [==============================] - 229s 6ms/step - loss: 1.2640 - acc: 0.5518 - val_loss: 1.1529 - val_acc: 0.5974\n",
            "Epoch 5/100\n",
            "40000/40000 [==============================] - 231s 6ms/step - loss: 1.1966 - acc: 0.5776 - val_loss: 1.1526 - val_acc: 0.5955\n",
            "Epoch 6/100\n",
            "40000/40000 [==============================] - 225s 6ms/step - loss: 1.1385 - acc: 0.6008 - val_loss: 1.0433 - val_acc: 0.6339\n",
            "Epoch 7/100\n",
            "40000/40000 [==============================] - 392s 10ms/step - loss: 1.0883 - acc: 0.6205 - val_loss: 1.0250 - val_acc: 0.6447\n",
            "Epoch 8/100\n",
            "40000/40000 [==============================] - 460s 11ms/step - loss: 1.0565 - acc: 0.6325 - val_loss: 0.9632 - val_acc: 0.6665\n",
            "Epoch 9/100\n",
            "40000/40000 [==============================] - 463s 12ms/step - loss: 1.0268 - acc: 0.6416 - val_loss: 0.9574 - val_acc: 0.6707\n",
            "Epoch 10/100\n",
            "40000/40000 [==============================] - 471s 12ms/step - loss: 1.0033 - acc: 0.6550 - val_loss: 0.9774 - val_acc: 0.6651\n",
            "Epoch 11/100\n",
            "40000/40000 [==============================] - 458s 11ms/step - loss: 0.9847 - acc: 0.6600 - val_loss: 0.9086 - val_acc: 0.6898\n",
            "Epoch 12/100\n",
            "40000/40000 [==============================] - 469s 12ms/step - loss: 0.9679 - acc: 0.6685 - val_loss: 0.9529 - val_acc: 0.6775\n",
            "Epoch 13/100\n",
            "40000/40000 [==============================] - 469s 12ms/step - loss: 0.9634 - acc: 0.6715 - val_loss: 0.9064 - val_acc: 0.6882\n",
            "Epoch 14/100\n",
            "40000/40000 [==============================] - 463s 12ms/step - loss: 0.9459 - acc: 0.6789 - val_loss: 0.9989 - val_acc: 0.6769\n",
            "Epoch 15/100\n",
            "40000/40000 [==============================] - 464s 12ms/step - loss: 0.9286 - acc: 0.6843 - val_loss: 0.9182 - val_acc: 0.6902\n",
            "Epoch 16/100\n",
            "40000/40000 [==============================] - 473s 12ms/step - loss: 0.9267 - acc: 0.6869 - val_loss: 0.9028 - val_acc: 0.6955\n",
            "Epoch 17/100\n",
            "40000/40000 [==============================] - 469s 12ms/step - loss: 0.9299 - acc: 0.6894 - val_loss: 0.8877 - val_acc: 0.7013\n",
            "Epoch 18/100\n",
            "40000/40000 [==============================] - 465s 12ms/step - loss: 0.9196 - acc: 0.6898 - val_loss: 0.9310 - val_acc: 0.6915\n",
            "Epoch 19/100\n",
            "40000/40000 [==============================] - 450s 11ms/step - loss: 0.9113 - acc: 0.6950 - val_loss: 0.9180 - val_acc: 0.7027\n",
            "Epoch 20/100\n",
            "40000/40000 [==============================] - 448s 11ms/step - loss: 0.9074 - acc: 0.6969 - val_loss: 0.8792 - val_acc: 0.7050\n",
            "Epoch 21/100\n",
            "40000/40000 [==============================] - 452s 11ms/step - loss: 0.8953 - acc: 0.6984 - val_loss: 0.8915 - val_acc: 0.7122\n",
            "Epoch 22/100\n",
            "40000/40000 [==============================] - 465s 12ms/step - loss: 0.8950 - acc: 0.7032 - val_loss: 0.8589 - val_acc: 0.7156\n",
            "Epoch 23/100\n",
            "40000/40000 [==============================] - 459s 11ms/step - loss: 0.8865 - acc: 0.7039 - val_loss: 0.8938 - val_acc: 0.7030\n",
            "Epoch 24/100\n",
            "40000/40000 [==============================] - 457s 11ms/step - loss: 0.8871 - acc: 0.7023 - val_loss: 0.8895 - val_acc: 0.7026\n",
            "Epoch 25/100\n",
            "40000/40000 [==============================] - 465s 12ms/step - loss: 0.8855 - acc: 0.7039 - val_loss: 0.8575 - val_acc: 0.7170\n",
            "Epoch 26/100\n",
            "40000/40000 [==============================] - 462s 12ms/step - loss: 0.8838 - acc: 0.7073 - val_loss: 0.8609 - val_acc: 0.7186\n",
            "Epoch 27/100\n",
            "40000/40000 [==============================] - 462s 12ms/step - loss: 0.8813 - acc: 0.7084 - val_loss: 0.9146 - val_acc: 0.6999\n",
            "Epoch 28/100\n",
            "40000/40000 [==============================] - 453s 11ms/step - loss: 0.8791 - acc: 0.7083 - val_loss: 0.8731 - val_acc: 0.7197\n",
            "Epoch 29/100\n",
            "40000/40000 [==============================] - 447s 11ms/step - loss: 0.8807 - acc: 0.7097 - val_loss: 0.9730 - val_acc: 0.7035\n",
            "Epoch 30/100\n",
            "40000/40000 [==============================] - 448s 11ms/step - loss: 0.8653 - acc: 0.7144 - val_loss: 0.8743 - val_acc: 0.7049\n",
            "Epoch 31/100\n",
            "40000/40000 [==============================] - 453s 11ms/step - loss: 0.8658 - acc: 0.7128 - val_loss: 0.8846 - val_acc: 0.7207\n",
            "Epoch 32/100\n",
            "40000/40000 [==============================] - 462s 12ms/step - loss: 0.8668 - acc: 0.7111 - val_loss: 0.8337 - val_acc: 0.7215\n",
            "Epoch 33/100\n",
            "40000/40000 [==============================] - 455s 11ms/step - loss: 0.8662 - acc: 0.7145 - val_loss: 0.8711 - val_acc: 0.7238\n",
            "Epoch 34/100\n",
            "40000/40000 [==============================] - 452s 11ms/step - loss: 0.8667 - acc: 0.7135 - val_loss: 0.9023 - val_acc: 0.7112\n",
            "Epoch 35/100\n",
            "40000/40000 [==============================] - 454s 11ms/step - loss: 0.8644 - acc: 0.7168 - val_loss: 0.8434 - val_acc: 0.7201\n",
            "Epoch 36/100\n",
            "40000/40000 [==============================] - 455s 11ms/step - loss: 0.8626 - acc: 0.7143 - val_loss: 0.8411 - val_acc: 0.7307\n",
            "Epoch 37/100\n",
            "40000/40000 [==============================] - 461s 12ms/step - loss: 0.8612 - acc: 0.7170 - val_loss: 0.8618 - val_acc: 0.7170\n",
            "Epoch 38/100\n",
            "40000/40000 [==============================] - 463s 12ms/step - loss: 0.8663 - acc: 0.7145 - val_loss: 0.8616 - val_acc: 0.7209\n",
            "Epoch 39/100\n",
            "40000/40000 [==============================] - 467s 12ms/step - loss: 0.8660 - acc: 0.7163 - val_loss: 0.8883 - val_acc: 0.7143\n",
            "Epoch 40/100\n",
            "40000/40000 [==============================] - 454s 11ms/step - loss: 0.8656 - acc: 0.7156 - val_loss: 0.8550 - val_acc: 0.7138\n",
            "Epoch 41/100\n",
            "40000/40000 [==============================] - 455s 11ms/step - loss: 0.8596 - acc: 0.7156 - val_loss: 0.8712 - val_acc: 0.7232\n",
            "Epoch 42/100\n",
            "40000/40000 [==============================] - 454s 11ms/step - loss: 0.8676 - acc: 0.7158 - val_loss: 0.8716 - val_acc: 0.7200\n",
            "Epoch 43/100\n",
            "40000/40000 [==============================] - 460s 11ms/step - loss: 0.8647 - acc: 0.7164 - val_loss: 0.9207 - val_acc: 0.7142\n",
            "Epoch 44/100\n",
            "40000/40000 [==============================] - 457s 11ms/step - loss: 0.8680 - acc: 0.7162 - val_loss: 0.8335 - val_acc: 0.7273\n",
            "Epoch 45/100\n",
            "40000/40000 [==============================] - 482s 12ms/step - loss: 0.8729 - acc: 0.7146 - val_loss: 0.8788 - val_acc: 0.7200\n",
            "Epoch 46/100\n",
            "40000/40000 [==============================] - 469s 12ms/step - loss: 0.8679 - acc: 0.7165 - val_loss: 0.9046 - val_acc: 0.7049\n",
            "Epoch 47/100\n",
            "33824/40000 [========================>.....] - ETA: 1:06 - loss: 0.8746 - acc: 0.7155Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "CSDcW0_dhLt_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "history_dict = history.history\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs_range = range(1, epochs+1)\n",
        "\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs_range, val_loss, 'ro', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iRW2yZKZhMHt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "acc = history_dict['acc']\n",
        "val_acc = history_dict['val_acc']\n",
        "\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, 'ro', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}